{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-Z_h-5kGi0",
        "outputId": "4aad0842-3b1d-4636-c105-3c3dd8fc842b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ],
      "source": [
        "! pip install torchviz -q\n",
        "! pip install torch-summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aUldvkRv9R-c"
      },
      "outputs": [],
      "source": [
        "# namespaces\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'notebook'\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "import joblib\n",
        "import math\n",
        "\n",
        "# functions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchsummary import summary\n",
        "from google.colab import files\n",
        "from timeit import default_timer as timer\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ISwmp2Cx8ch2"
      },
      "outputs": [],
      "source": [
        "# get data, drop index column and zero the blanks\n",
        "places_df = pd.read_csv('https://raw.githubusercontent.com/markstiles/us-data-analysis/main/places_data.csv')\n",
        "places_df.drop(places_df.columns[[0]], axis=1, inplace=True)\n",
        "places_df = places_df.fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fkwKah1P8ZKf"
      },
      "outputs": [],
      "source": [
        "# build a one-hot by state and attach it\n",
        "state_dummies = pd.get_dummies(places_df.State_Name)\n",
        "places_df = pd.concat([places_df, state_dummies.set_axis(places_df.index)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "eBf7fKnrCpdo"
      },
      "outputs": [],
      "source": [
        "#@title Drop Column List\n",
        "# get rid of the locations and sparse data\n",
        "drop_cols = [\n",
        " 'Place_Name', 'State_Abbr', 'State_Name', 'Type', 'All_Employers', 'All_Employees', 'All_Payroll',\n",
        " 'Agriculture_Employers','Agriculture_Employees','Agriculture_Payroll','Agriculture_Revenue',\n",
        " 'Construction_Employers','Construction_Employees','Construction_Payroll','Construction_Revenue',\n",
        " 'Finance_Revenue',\n",
        " 'Information_Revenue',\n",
        " 'Management_Employers','Management_Employees','Management_Payroll','Management_Revenue',\n",
        " 'Manufacturing_Employers','Manufacturing_Employees','Manufacturing_Payroll','Manufacturing_Revenue',\n",
        " 'Mining_Employers','Mining_Employees','Mining_Payroll','Mining_Revenue',\n",
        " 'Utilities_Revenue',\n",
        " 'Wholesale_Employers','Wholesale_Employees','Wholesale_Payroll','Wholesale_Revenue',\n",
        " 'Consumer_Total_Expense','Consumer_Expense_Alcohol','Consumer_Expense_Alcohol_Home','Consumer_Expense_Beer_Bar','Consumer_Expense_Wine_Bar','Consumer_Expense_Clothes','Consumer_Expense_Mens_Clothes',\n",
        " 'Consumer_Expense_Womens_Clothes','Consumer_Expense_Childrens_Clothes','Consumer_Expense_Boys_Clothes','Consumer_Expense_Girls_Clothes','Consumer_Expense_Footwear','Consumer_Expense_Dining',\n",
        " 'Consumer_Expense_Dining_Breakfast','Consumer_Expense_Dining_Lunch','Consumer_Expense_Dining_Dinner','Consumer_Expense_Education','Consumer_Expense_Entertainment','Consumer_Expense_Clubs',\n",
        " 'Consumer_Expense_Dating','Consumer_Expense_Pet_Food','Consumer_Expense_Pet_Services','Consumer_Expense_Food_Home','Consumer_Expense_Bakery_Home','Consumer_Expense_Dairy_Home','Consumer_Expense_Fruits_Home',\n",
        " 'Consumer_Expense_Meat_Home','Consumer_Expense_Nonalcohol_Home','Consumer_Expense_Snacks_Home','Consumer_Expense_Healthcare','Consumer_Expense_Mentalcare','Consumer_Expense_Drugcar','Consumer_Expense_House_Services',\n",
        " 'Consumer_Expense_Eldercare','Consumer_Expense_Landscape','Consumer_Expense_Housekeeping','Consumer_Expense_PC','Consumer_Expense_Housing','Consumer_Expense_Home_Improvements','Consumer_Expense_Energy',\n",
        " 'Consumer_Expense_Phone','Consumer_Expense_Water','Consumer_Expense_Insurance','Consumer_Expense_Pensions','Consumer_Expense_Personalcare','Consumer_Expense_Haircare','Consumer_Expense_Personalcare_Products',\n",
        " 'Consumer_Expense_Transport','Consumer_Expense_Gas','Consumer_Expense_Vehicle_Repair','Consumer_Expense_Travel','Consumer_Expense_Airfare','Consumer_Expense_Auto_Rentals','Consumer_Expense_Travel_Lodging',\n",
        " 'Consumer_Expense_Travel_Meals','Consumer_Expense_Travel_Entertainment',\n",
        " 'All_Employee_Per_Employer','All_Revenue_Per_Employer','All_Avg_Payroll_Per_Employee','All_Population_Per_Employer',\n",
        " 'Food_Services_Employee_Per_Employer','Food_Services_Revenue_Per_Employer','Food_Services_Avg_Payroll_Per_Employee','Food_Services_Population_Per_Employer','Waste_Management_Employee_Per_Employer',\n",
        " 'Waste_Management_Revenue_Per_Employer','Waste_Management_Avg_Payroll_Per_Employee','Waste_Management_Population_Per_Employer','Agriculture_Employee_Per_Employer','Agriculture_Revenue_Per_Employer',\n",
        " 'Agriculture_Avg_Payroll_Per_Employee','Agriculture_Population_Per_Employer','Arts_Employee_Per_Employer','Arts_Revenue_Per_Employer','Arts_Avg_Payroll_Per_Employee','Arts_Population_Per_Employer',\n",
        " 'Construction_Employee_Per_Employer','Construction_Revenue_Per_Employer','Construction_Avg_Payroll_Per_Employee','Construction_Population_Per_Employer','Education_Employee_Per_Employer',\n",
        " 'Education_Revenue_Per_Employer','Education_Avg_Payroll_Per_Employee','Education_Population_Per_Employer','Finance_Employee_Per_Employer','Finance_Revenue_Per_Employer','Finance_Avg_Payroll_Per_Employee',\n",
        " 'Finance_Population_Per_Employer','Healthcare_Employee_Per_Employer','Healthcare_Revenue_Per_Employer','Healthcare_Avg_Payroll_Per_Employee','Healthcare_Population_Per_Employer','Information_Employee_Per_Employer',\n",
        " 'Information_Revenue_Per_Employer','Information_Avg_Payroll_Per_Employee','Information_Population_Per_Employer','Management_Employee_Per_Employer','Management_Revenue_Per_Employer','Management_Avg_Payroll_Per_Employee',\n",
        " 'Management_Population_Per_Employer','Manufacturing_Employee_Per_Employer','Manufacturing_Revenue_Per_Employer','Manufacturing_Avg_Payroll_Per_Employee','Manufacturing_Population_Per_Employer','Mining_Employee_Per_Employer',\n",
        " 'Mining_Revenue_Per_Employer','Mining_Avg_Payroll_Per_Employee','Mining_Population_Per_Employer','Other_Employee_Per_Employer','Other_Revenue_Per_Employer','Other_Avg_Payroll_Per_Employee','Other_Population_Per_Employer',\n",
        " 'Technical_Employee_Per_Employer','Technical_Revenue_Per_Employer','Technical_Avg_Payroll_Per_Employee','Technical_Population_Per_Employer','Real_Estate_Employee_Per_Employer','Real_Estate_Revenue_Per_Employer',\n",
        " 'Real_Estate_Avg_Payroll_Per_Employee','Real_Estate_Population_Per_Employer','Retail_Employee_Per_Employer','Retail_Revenue_Per_Employer','Retail_Avg_Payroll_Per_Employee','Retail_Population_Per_Employer',\n",
        " 'Transportation_Employee_Per_Employer','Transportation_Revenue_Per_Employer','Transportation_Avg_Payroll_Per_Employee','Transportation_Population_Per_Employer','Utilities_Employee_Per_Employer','Utilities_Revenue_Per_Employer',\n",
        " 'Utilities_Avg_Payroll_Per_Employee','Utilities_Population_Per_Employer','Wholesale_Employee_Per_Employer','Wholesale_Revenue_Per_Employer','Wholesale_Avg_Payroll_Per_Employee','Wholesale_Population_Per_Employer',\n",
        " 'Income_Per_Revenue',\n",
        " 'Revenue_Per_Person','Profit_Per_Person',\n",
        " 'Population_Range', 'Performance'\n",
        "]\n",
        "places_df.drop(columns=drop_cols, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kJi7oGtH9QYd"
      },
      "outputs": [],
      "source": [
        "# drop the top skewing outliers\n",
        "places_df = places_df[places_df.All_Revenue < 20000000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_tAU7mwGT0K",
        "outputId": "7f0577a2-d3ec-490b-f432-f1016bf78868"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9720, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# set the y to revenue\n",
        "y = places_df['All_Revenue'].to_numpy()\n",
        "# remove the identifier and target columns\n",
        "x = places_df.drop(columns=['GeoId', 'All_Revenue'])\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mr9DFVB-Wp08"
      },
      "outputs": [],
      "source": [
        "# train-test split for model evaluation\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75, shuffle=True)\n",
        "\n",
        "# normalize\n",
        "scaler = StandardScaler()\n",
        "#scaler = MinMaxScaler()\n",
        "scaler.fit(x_train)\n",
        "\n",
        "# scale the data\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "# convert to 2d pytorch tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yie30pB_HIED"
      },
      "outputs": [],
      "source": [
        "# define the model\n",
        "# 2048 -> 2048 -> 2048 -> 1 was a good model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(x.shape[1], 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100, 1)\n",
        ")\n",
        "\n",
        "# set the weights for the regression model\n",
        "def init_weights_xavier(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "def init_weights_uniform(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "      n = m.in_features\n",
        "      y = 1.0/np.sqrt(n)\n",
        "      m.weight.data.uniform_(-y, y)\n",
        "      m.bias.data.fill_(0)\n",
        "\n",
        "#model.apply(init_weights_uniform)\n",
        "\n",
        "# loss function and optimizer\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wUhcWE73S4aZ"
      },
      "outputs": [],
      "source": [
        "# hold the best model\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "train_history = []\n",
        "test_history = []\n",
        "\n",
        "n_epochs = 10000   # number of epochs to run\n",
        "batch_size = 500  # size of each batch\n",
        "batch_start = torch.arange(0, len(x_train), batch_size)\n",
        "step_count = 0\n",
        "step_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_DLk-V_S5SZ",
        "outputId": "205ea0ba-cfac-4c39-af7a-00c2950105d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 15/15 [00:00<00:00, 41.56batch/s, mse=1.53e+12]\n",
            "Epoch 1: 100%|██████████| 15/15 [00:00<00:00, 64.84batch/s, mse=1.53e+12]\n",
            "Epoch 2: 100%|██████████| 15/15 [00:00<00:00, 61.68batch/s, mse=1.52e+12]\n",
            "Epoch 3: 100%|██████████| 15/15 [00:00<00:00, 64.43batch/s, mse=1.47e+12]\n",
            "Epoch 4: 100%|██████████| 15/15 [00:00<00:00, 63.24batch/s, mse=1.02e+12]\n",
            "Epoch 5: 100%|██████████| 15/15 [00:00<00:00, 64.93batch/s, mse=2.51e+11]\n",
            "Epoch 6: 100%|██████████| 15/15 [00:00<00:00, 58.46batch/s, mse=1.66e+11]\n",
            "Epoch 7: 100%|██████████| 15/15 [00:00<00:00, 62.68batch/s, mse=1.4e+11]\n",
            "Epoch 8: 100%|██████████| 15/15 [00:00<00:00, 66.07batch/s, mse=1.18e+11]\n",
            "Epoch 9: 100%|██████████| 15/15 [00:00<00:00, 65.61batch/s, mse=1.04e+11]\n",
            "Epoch 10: 100%|██████████| 15/15 [00:00<00:00, 64.40batch/s, mse=9.23e+10]\n",
            "Epoch 11: 100%|██████████| 15/15 [00:00<00:00, 63.47batch/s, mse=8.27e+10]\n",
            "Epoch 12: 100%|██████████| 15/15 [00:00<00:00, 67.97batch/s, mse=7.44e+10]\n",
            "Epoch 13: 100%|██████████| 15/15 [00:00<00:00, 62.24batch/s, mse=6.73e+10]\n",
            "Epoch 14: 100%|██████████| 15/15 [00:00<00:00, 63.50batch/s, mse=6.12e+10]\n",
            "Epoch 15: 100%|██████████| 15/15 [00:00<00:00, 67.40batch/s, mse=5.57e+10]\n",
            "Epoch 16: 100%|██████████| 15/15 [00:00<00:00, 64.44batch/s, mse=5.08e+10]\n",
            "Epoch 17: 100%|██████████| 15/15 [00:00<00:00, 63.10batch/s, mse=4.66e+10]\n",
            "Epoch 18: 100%|██████████| 15/15 [00:00<00:00, 63.63batch/s, mse=4.27e+10]\n",
            "Epoch 19: 100%|██████████| 15/15 [00:00<00:00, 63.16batch/s, mse=3.92e+10]\n",
            "Epoch 20: 100%|██████████| 15/15 [00:00<00:00, 56.62batch/s, mse=3.63e+10]\n",
            "Epoch 21: 100%|██████████| 15/15 [00:00<00:00, 60.15batch/s, mse=3.37e+10]\n",
            "Epoch 22: 100%|██████████| 15/15 [00:00<00:00, 55.73batch/s, mse=3.14e+10]\n",
            "Epoch 23: 100%|██████████| 15/15 [00:00<00:00, 59.78batch/s, mse=2.95e+10]\n",
            "Epoch 24: 100%|██████████| 15/15 [00:00<00:00, 55.32batch/s, mse=2.77e+10]\n",
            "Epoch 25: 100%|██████████| 15/15 [00:00<00:00, 51.14batch/s, mse=2.61e+10]\n",
            "Epoch 26: 100%|██████████| 15/15 [00:00<00:00, 51.67batch/s, mse=2.46e+10]\n",
            "Epoch 27: 100%|██████████| 15/15 [00:00<00:00, 55.18batch/s, mse=2.32e+10]\n",
            "Epoch 28: 100%|██████████| 15/15 [00:00<00:00, 56.93batch/s, mse=2.2e+10]\n",
            "Epoch 29: 100%|██████████| 15/15 [00:00<00:00, 61.16batch/s, mse=2.09e+10]\n",
            "Epoch 30: 100%|██████████| 15/15 [00:00<00:00, 61.49batch/s, mse=1.98e+10]\n",
            "Epoch 31: 100%|██████████| 15/15 [00:00<00:00, 56.36batch/s, mse=1.89e+10]\n",
            "Epoch 32: 100%|██████████| 15/15 [00:00<00:00, 54.03batch/s, mse=1.8e+10]\n",
            "Epoch 33: 100%|██████████| 15/15 [00:00<00:00, 53.73batch/s, mse=1.71e+10]\n",
            "Epoch 34: 100%|██████████| 15/15 [00:00<00:00, 59.78batch/s, mse=1.64e+10]\n",
            "Epoch 35: 100%|██████████| 15/15 [00:00<00:00, 60.18batch/s, mse=1.56e+10]\n",
            "Epoch 36: 100%|██████████| 15/15 [00:00<00:00, 58.90batch/s, mse=1.5e+10]\n",
            "Epoch 37: 100%|██████████| 15/15 [00:00<00:00, 63.17batch/s, mse=1.43e+10]\n",
            "Epoch 38: 100%|██████████| 15/15 [00:00<00:00, 52.75batch/s, mse=1.38e+10]\n",
            "Epoch 39: 100%|██████████| 15/15 [00:00<00:00, 62.21batch/s, mse=1.32e+10]\n",
            "Epoch 40: 100%|██████████| 15/15 [00:00<00:00, 55.65batch/s, mse=1.27e+10]\n",
            "Epoch 41: 100%|██████████| 15/15 [00:00<00:00, 60.36batch/s, mse=1.22e+10]\n",
            "Epoch 42: 100%|██████████| 15/15 [00:00<00:00, 59.16batch/s, mse=1.18e+10]\n",
            "Epoch 43: 100%|██████████| 15/15 [00:00<00:00, 59.03batch/s, mse=1.14e+10]\n",
            "Epoch 44: 100%|██████████| 15/15 [00:00<00:00, 57.70batch/s, mse=1.1e+10]\n",
            "Epoch 45: 100%|██████████| 15/15 [00:00<00:00, 59.02batch/s, mse=1.06e+10]\n",
            "Epoch 46: 100%|██████████| 15/15 [00:00<00:00, 58.90batch/s, mse=1.03e+10]\n",
            "Epoch 47: 100%|██████████| 15/15 [00:00<00:00, 59.54batch/s, mse=9.93e+9]\n",
            "Epoch 48: 100%|██████████| 15/15 [00:00<00:00, 57.29batch/s, mse=9.62e+9]\n",
            "Epoch 49: 100%|██████████| 15/15 [00:00<00:00, 65.13batch/s, mse=9.33e+9]\n",
            "Epoch 50: 100%|██████████| 15/15 [00:00<00:00, 63.82batch/s, mse=9.05e+9]\n",
            "Epoch 51: 100%|██████████| 15/15 [00:00<00:00, 57.15batch/s, mse=8.8e+9]\n",
            "Epoch 52: 100%|██████████| 15/15 [00:00<00:00, 50.10batch/s, mse=8.56e+9]\n",
            "Epoch 53: 100%|██████████| 15/15 [00:00<00:00, 48.79batch/s, mse=8.33e+9]\n",
            "Epoch 54: 100%|██████████| 15/15 [00:00<00:00, 52.64batch/s, mse=8.11e+9]\n",
            "Epoch 55: 100%|██████████| 15/15 [00:00<00:00, 56.00batch/s, mse=7.91e+9]\n",
            "Epoch 56: 100%|██████████| 15/15 [00:00<00:00, 54.18batch/s, mse=7.72e+9]\n",
            "Epoch 57: 100%|██████████| 15/15 [00:00<00:00, 53.76batch/s, mse=7.54e+9]\n",
            "Epoch 58: 100%|██████████| 15/15 [00:00<00:00, 49.62batch/s, mse=7.37e+9]\n",
            "Epoch 59: 100%|██████████| 15/15 [00:00<00:00, 58.26batch/s, mse=7.21e+9]\n",
            "Epoch 60: 100%|██████████| 15/15 [00:00<00:00, 52.83batch/s, mse=7.05e+9]\n",
            "Epoch 61: 100%|██████████| 15/15 [00:00<00:00, 58.06batch/s, mse=6.9e+9]\n",
            "Epoch 62: 100%|██████████| 15/15 [00:00<00:00, 63.65batch/s, mse=6.77e+9]\n",
            "Epoch 63: 100%|██████████| 15/15 [00:00<00:00, 63.72batch/s, mse=6.63e+9]\n",
            "Epoch 64: 100%|██████████| 15/15 [00:00<00:00, 62.63batch/s, mse=6.5e+9]\n",
            "Epoch 65: 100%|██████████| 15/15 [00:00<00:00, 63.19batch/s, mse=6.38e+9]\n",
            "Epoch 66: 100%|██████████| 15/15 [00:00<00:00, 63.40batch/s, mse=6.27e+9]\n",
            "Epoch 67: 100%|██████████| 15/15 [00:00<00:00, 66.35batch/s, mse=6.15e+9]\n",
            "Epoch 68: 100%|██████████| 15/15 [00:00<00:00, 62.87batch/s, mse=6.04e+9]\n",
            "Epoch 69: 100%|██████████| 15/15 [00:00<00:00, 63.18batch/s, mse=5.93e+9]\n",
            "Epoch 70: 100%|██████████| 15/15 [00:00<00:00, 64.22batch/s, mse=5.82e+9]\n",
            "Epoch 71: 100%|██████████| 15/15 [00:00<00:00, 62.74batch/s, mse=5.72e+9]\n",
            "Epoch 72: 100%|██████████| 15/15 [00:00<00:00, 69.02batch/s, mse=5.63e+9]\n",
            "Epoch 73: 100%|██████████| 15/15 [00:00<00:00, 55.79batch/s, mse=5.54e+9]\n",
            "Epoch 74: 100%|██████████| 15/15 [00:00<00:00, 62.98batch/s, mse=5.45e+9]\n",
            "Epoch 75: 100%|██████████| 15/15 [00:00<00:00, 64.72batch/s, mse=5.36e+9]\n",
            "Epoch 76: 100%|██████████| 15/15 [00:00<00:00, 66.06batch/s, mse=5.28e+9]\n",
            "Epoch 77: 100%|██████████| 15/15 [00:00<00:00, 59.53batch/s, mse=5.2e+9]\n",
            "Epoch 78: 100%|██████████| 15/15 [00:00<00:00, 62.42batch/s, mse=5.12e+9]\n",
            "Epoch 79: 100%|██████████| 15/15 [00:00<00:00, 64.76batch/s, mse=5.05e+9]\n",
            "Epoch 80: 100%|██████████| 15/15 [00:00<00:00, 64.64batch/s, mse=4.98e+9]\n",
            "Epoch 81: 100%|██████████| 15/15 [00:00<00:00, 61.12batch/s, mse=4.91e+9]\n",
            "Epoch 82: 100%|██████████| 15/15 [00:00<00:00, 62.98batch/s, mse=4.84e+9]\n",
            "Epoch 83: 100%|██████████| 15/15 [00:00<00:00, 66.82batch/s, mse=4.77e+9]\n",
            "Epoch 84: 100%|██████████| 15/15 [00:00<00:00, 62.21batch/s, mse=4.71e+9]\n",
            "Epoch 85: 100%|██████████| 15/15 [00:00<00:00, 61.48batch/s, mse=4.65e+9]\n",
            "Epoch 86: 100%|██████████| 15/15 [00:00<00:00, 61.80batch/s, mse=4.59e+9]\n",
            "Epoch 87: 100%|██████████| 15/15 [00:00<00:00, 66.43batch/s, mse=4.53e+9]\n",
            "Epoch 88: 100%|██████████| 15/15 [00:00<00:00, 62.07batch/s, mse=4.48e+9]\n",
            "Epoch 89: 100%|██████████| 15/15 [00:00<00:00, 57.91batch/s, mse=4.43e+9]\n",
            "Epoch 90: 100%|██████████| 15/15 [00:00<00:00, 61.75batch/s, mse=4.37e+9]\n",
            "Epoch 91: 100%|██████████| 15/15 [00:00<00:00, 61.13batch/s, mse=4.32e+9]\n",
            "Epoch 92: 100%|██████████| 15/15 [00:00<00:00, 62.29batch/s, mse=4.28e+9]\n",
            "Epoch 93: 100%|██████████| 15/15 [00:00<00:00, 59.71batch/s, mse=4.23e+9]\n",
            "Epoch 94:  73%|███████▎  | 11/15 [00:00<00:00, 66.34batch/s, mse=9.66e+9]"
          ]
        }
      ],
      "source": [
        "start_time = timer()\n",
        "\n",
        "# train and store progress\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=False) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            x_batch = x_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            mse = float(loss)\n",
        "            if mse < best_mse:\n",
        "              best_mse = mse\n",
        "              best_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "            if step_count % step_size == 0:\n",
        "              train_history.append(loss.item())\n",
        "              with torch.no_grad():\n",
        "                  y_test_pred = model(x_test)\n",
        "                  test_loss = loss_fn(y_test_pred.float(), y_test)\n",
        "                  test_history.append(test_loss.item())\n",
        "\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "\n",
        "            step_count += 1\n",
        "\n",
        "end_time = timer()\n",
        "print(timedelta(seconds=end_time-start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGnRdRAFTRWa"
      },
      "outputs": [],
      "source": [
        "# restore model and return best accuracy\n",
        "model.load_state_dict(best_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn-QQiwNAoh1"
      },
      "outputs": [],
      "source": [
        "model_filename = 'places_model.pt'\n",
        "torch.save(model.state_dict(), model_filename)\n",
        "files.download(model_filename)\n",
        "\n",
        "scaler_filename = \"scaler.save\"\n",
        "joblib.dump(scaler, scaler_filename)\n",
        "files.download(scaler_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8pAEhohTPtk"
      },
      "outputs": [],
      "source": [
        "blue_patch = mpatches.Patch(color = 'blue', label = 'Train MSE')\n",
        "orange_patch = mpatches.Patch(color = 'orange', label = 'Validation MSE')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.lineplot(x=range(1,len(train_history)+1),y = train_history)\n",
        "sns.lineplot(x=range(1,len(test_history)+1),y = test_history)\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend(handles = [blue_patch,orange_patch])\n",
        "plt.title('Training and Validation loss');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIQKqlZVCm80"
      },
      "outputs": [],
      "source": [
        "# give it a test on my hometown\n",
        "waltham = places_df[places_df.GeoId==2572600]\n",
        "actual = waltham.iloc[0].All_Revenue\n",
        "waltham_scaled = scaler.transform(waltham.drop(columns=['GeoId', 'All_Revenue']))\n",
        "prediction = model(torch.tensor(waltham_scaled, dtype=torch.float32)).item()\n",
        "print(f'actual: {int(actual):,}')\n",
        "print(f'predicted: {int(prediction):,}')\n",
        "diff = int(abs(prediction-actual))\n",
        "print(f'difference: {diff:,}')\n",
        "percent_diff = int((diff/actual)*100)\n",
        "print(f'percent difference: {percent_diff:,}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}