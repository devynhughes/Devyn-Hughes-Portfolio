{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Original Code**"
      ],
      "metadata": {
        "id": "sadUI9QiP6uP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ1HyN1rAWGx",
        "outputId": "d165713c-7e15-4c6c-db01-c3f45827d10b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 29.4118\n",
            "Epoch 2, Loss: 29.4118\n",
            "Epoch 3, Loss: 41.1765\n",
            "Epoch 4, Loss: 23.5294\n",
            "Epoch 5, Loss: 35.2941\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "\n",
        "# Load data\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
        "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", names=column_names, sep=r'\\s*,\\s*', engine='python')\n",
        "\n",
        "# Preprocess data\n",
        "data['income'] = data['income'].apply(lambda x: 0 if x == \"<=50K\" else 1)\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "numerical_columns = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "\n",
        "for category in categorical_columns:\n",
        "    data[category] = data[category].astype('category').cat.codes\n",
        "\n",
        "data = data.sample(frac=1).reset_index(drop=True)  # Shuffle data\n",
        "#import pdb; pdb.set_trace()\n",
        "# Create DataLoader\n",
        "X = torch.tensor(data[categorical_columns + numerical_columns].values, dtype=torch.float32)\n",
        "y = torch.tensor(data['income'].values, dtype=torch.float32)\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define neural network with embeddings\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # import pdb; pdb.set_trace() # cursor here\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), 10) for column in categorical_columns])\n",
        "        self.fc1 = nn.Linear(10*len(categorical_columns) + len(numerical_columns), 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    for batch_X, batch_y in loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Test and Train Data**"
      ],
      "metadata": {
        "id": "P_wkMQ3NXZiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "B5XhjPh7XkYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the Train DataLoader\n",
        "train_x = torch.tensor(train_data[categorical_columns + numerical_columns].values, dtype=torch.float32)\n",
        "train_y = torch.tensor(train_data['income'].values, dtype=torch.float32)\n",
        "train_dataset = TensorDataset(train_x, train_y)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "aV_RlsxWbXPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the Test DataLoader\n",
        "X = torch.tensor(test_data[categorical_columns + numerical_columns].values, dtype=torch.float32)\n",
        "y = torch.tensor(test_data['income'].values, dtype=torch.float32)\n",
        "test_dataset = TensorDataset(X, y)\n",
        "test_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "qdvUyfR3Pwwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate The Original Code's Accuracy**"
      ],
      "metadata": {
        "id": "6TzZdLlcP1bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define neural network with embeddings\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # import pdb; pdb.set_trace() # cursor here\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), 10) for column in categorical_columns])\n",
        "        self.fc1 = nn.Linear(10*len(categorical_columns) + len(numerical_columns), 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENOtFhgfP08o",
        "outputId": "d5e35d45-ba4c-4926-fcb0-1a799461f35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 70.5882\n",
            "Epoch 2, Loss: 94.1176\n",
            "Epoch 3, Loss: 76.4706\n",
            "Epoch 4, Loss: 70.5882\n",
            "Epoch 5, Loss: 70.5882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMAG6XE4RLVz",
        "outputId": "e98bd69e-088d-403b-c17d-a9b8b029729a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 24.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Changing the Layers and Length**"
      ],
      "metadata": {
        "id": "ZVHNoYOGR_9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define neural network with embeddings\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # import pdb; pdb.set_trace() # cursor here\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), 5) for column in categorical_columns])\n",
        "        self.fc1 = nn.Linear(5*len(categorical_columns) + len(numerical_columns), 25)\n",
        "        self.fc2 = nn.Linear(25,10)\n",
        "        self.fc3 = nn.Linear(10, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcDqj-3PclpY",
        "outputId": "a89505d9-9b59-456e-a96e-723e59a11fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6113\n",
            "Epoch 2, Loss: 0.6130\n",
            "Epoch 3, Loss: 0.4799\n",
            "Epoch 4, Loss: 0.3283\n",
            "Epoch 5, Loss: 0.5458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJD3y8tPgCa0",
        "outputId": "441d95a6-a847-438d-d5a2-d08122cde4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Changing The Model Back to Original Lengths with the Additional Layer**\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "EsuDLcsqAo6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define neural network with embeddings\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # import pdb; pdb.set_trace() # cursor here\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), 10) for column in categorical_columns])\n",
        "        self.fc1 = nn.Linear(10*len(categorical_columns) + len(numerical_columns), 50)\n",
        "        self.fc2 = nn.Linear(50,10)\n",
        "        self.fc3 = nn.Linear(10, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        x = self.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "LZbShIjVAwzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28a8ce1-b25f-4b86-e3b0-6c313e0b5c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4104\n",
            "Epoch 2, Loss: 0.6134\n",
            "Epoch 3, Loss: 0.5983\n",
            "Epoch 4, Loss: 0.6145\n",
            "Epoch 5, Loss: 0.4772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ4Ikd8J8tIP",
        "outputId": "37b48a0f-276a-49fd-fd1f-e045597b24a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 75.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's Try Some Dropout Layers and Batch Normalization**\n"
      ],
      "metadata": {
        "id": "9ctVPdguG0VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 100)\n",
        "        self.bn1 = nn.BatchNorm1d(100)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "SWJVaLSJG5To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co5i44iFG-Fg",
        "outputId": "044ced6d-2e6d-4122-df18-909e7d3eb498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9038\n",
            "Epoch 2, Loss: 0.3152\n",
            "Epoch 3, Loss: 0.4358\n",
            "Epoch 4, Loss: 0.6756\n",
            "Epoch 5, Loss: 0.3248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyoikbEMLupv",
        "outputId": "7b106af2-5bf7-44b1-a646-e75859ece49b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.92%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Updating the Learning Rate**\n"
      ],
      "metadata": {
        "id": "qyNfdetALNWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 100)\n",
        "        self.bn1 = nn.BatchNorm1d(100)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ZsH-CeLYLSGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50CFomUYLdKy",
        "outputId": "d49deff1-5e6b-497d-e10f-1c5776f8a514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.4108\n",
            "Epoch 2, Loss: 0.4541\n",
            "Epoch 3, Loss: 0.2030\n",
            "Epoch 4, Loss: 0.1581\n",
            "Epoch 5, Loss: 0.3583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcjn9B9MO7tJ",
        "outputId": "c8deb567-d647-4aaa-dedd-c024e2ec1aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.79%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **increasing the Epochs**\n"
      ],
      "metadata": {
        "id": "le-TjSdAPA_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 100)\n",
        "        self.bn1 = nn.BatchNorm1d(100)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "SlFStcNuPAcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gylV7WDdPKWK",
        "outputId": "f726429f-6c06-4371-b2eb-e42b02a5ee06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6038\n",
            "Epoch 2, Loss: 0.3757\n",
            "Epoch 3, Loss: 0.7742\n",
            "Epoch 4, Loss: 0.3576\n",
            "Epoch 5, Loss: 0.4793\n",
            "Epoch 6, Loss: 0.3990\n",
            "Epoch 7, Loss: 0.3750\n",
            "Epoch 8, Loss: 0.5500\n",
            "Epoch 9, Loss: 0.5137\n",
            "Epoch 10, Loss: 0.3254\n",
            "Epoch 11, Loss: 0.4063\n",
            "Epoch 12, Loss: 0.4169\n",
            "Epoch 13, Loss: 0.6027\n",
            "Epoch 14, Loss: 0.3511\n",
            "Epoch 15, Loss: 0.4453\n",
            "Epoch 16, Loss: 0.3977\n",
            "Epoch 17, Loss: 0.2839\n",
            "Epoch 18, Loss: 0.3381\n",
            "Epoch 19, Loss: 0.4573\n",
            "Epoch 20, Loss: 0.1934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98hyzvBYZXxN",
        "outputId": "8fa07dfc-aaec-4394-fa53-f1707e35c9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 100)\n",
        "        self.bn1 = nn.BatchNorm1d(100)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "YW1oF5SLZhfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrR7RJKWZrrn",
        "outputId": "83a9f21a-6e23-468c-98ff-e402a88bde9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.6674\n",
            "Epoch 2, Loss: 0.4885\n",
            "Epoch 3, Loss: 0.3507\n",
            "Epoch 4, Loss: 0.3196\n",
            "Epoch 5, Loss: 0.2484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIDUQZAIdnN0",
        "outputId": "c20dcc9b-b307-40d4-c221-46de7f11bcb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attempted Adding a Fourth Layer within Network**"
      ],
      "metadata": {
        "id": "wAsnvJ6udsCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 200)\n",
        "        self.bn1 = nn.BatchNorm1d(200)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(200, 100)\n",
        "        self.bn2 = nn.BatchNorm1d(100)\n",
        "        self.dropout2 = nn.Dropout(0.2)\n",
        "\n",
        "        self.fc3 = nn.Linear(100,50)\n",
        "        self.bn3 = nn.BatchNorm1d(50)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "\n",
        "        self.fc4 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc4(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "6qAeBHMndrWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ra_mIoBXearV",
        "outputId": "0ceb3da8-d70a-452f-f767-7fc31bd555fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3563\n",
            "Epoch 2, Loss: 0.3362\n",
            "Epoch 3, Loss: 0.4057\n",
            "Epoch 4, Loss: 0.4572\n",
            "Epoch 5, Loss: 0.2940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8gbx6n7hlzy",
        "outputId": "33aed8bc-4a46-4350-d523-41b83fe43532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **All Sigmoid**"
      ],
      "metadata": {
        "id": "_7OamubHhw_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 100)\n",
        "        self.bn1 = nn.BatchNorm1d(100)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.sigmoid(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.sigmoid(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Ob6bMABvhwOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjT4w6QyiWv-",
        "outputId": "fea77d7f-215e-466c-ea55-af7fe0f3ff06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3109\n",
            "Epoch 2, Loss: 0.4953\n",
            "Epoch 3, Loss: 0.3526\n",
            "Epoch 4, Loss: 0.5317\n",
            "Epoch 5, Loss: 0.3232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8x9UCXrjnJqi",
        "outputId": "21efe123-30d9-4a57-b130-c5da88615aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 84.47%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Try To Use A Different Optimizer**\n"
      ],
      "metadata": {
        "id": "LxJYZCv-xjdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.embeddings = nn.ModuleList([nn.Embedding(len(data[column]), min(50, len(data[column]) // 2)) for column in categorical_columns])\n",
        "        embedding_dim = sum([min(50, len(data[column]) // 2) for column in categorical_columns])\n",
        "\n",
        "        self.fc1 = nn.Linear(embedding_dim + len(numerical_columns), 100)\n",
        "        self.bn1 = nn.BatchNorm1d(100)\n",
        "        self.dropout1 = nn.Dropout(0.4)\n",
        "\n",
        "        self.fc2 = nn.Linear(100, 50)\n",
        "        self.bn2 = nn.BatchNorm1d(50)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc3 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cat = x[:, :len(categorical_columns)].long()\n",
        "        x_num = x[:, len(categorical_columns):]\n",
        "        x_cat = [emb(x_cat[:, i]) for i, emb in enumerate(self.embeddings)]\n",
        "        x_cat = torch.cat(x_cat, 1)\n",
        "        x = torch.cat([x_cat, x_num], 1)\n",
        "\n",
        "        x = torch.sigmoid(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = torch.sigmoid(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x.squeeze()\n",
        "\n",
        "# Initialize and train the model\n",
        "model = Net()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adamax(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "XcuX1bDfxssR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(5):\n",
        "    for batch_train_x, batch_train_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_train_x)\n",
        "        loss = criterion(outputs, batch_train_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7SJAqQx7dJ",
        "outputId": "8d70dd79-c3ec-4398-ff5a-6d011329070c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.3300\n",
            "Epoch 2, Loss: 0.6270\n",
            "Epoch 3, Loss: 0.3911\n",
            "Epoch 4, Loss: 0.5439\n",
            "Epoch 5, Loss: 0.3218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for batch_test_x, batch_test_y in test_loader:\n",
        "        outputs = model(batch_test_x)\n",
        "        predicted = (outputs > 0.5).float()  # Assuming a binary classification problem\n",
        "        total += batch_test_y.size(0)\n",
        "        correct += (predicted == batch_test_y).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRmUE3Dgyx7l",
        "outputId": "d2b318c3-ebd2-4a5e-89aa-c0ffc912e037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 76.14%\n"
          ]
        }
      ]
    }
  ]
}